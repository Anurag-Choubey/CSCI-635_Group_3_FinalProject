{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stgt0h76-ST3"
      },
      "outputs": [],
      "source": [
        "#SECTION 1\n",
        "import time\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def load_dataset():\n",
        "    (ds_train, ds_test), ds_info = tfds.load(\n",
        "        'stanford_dogs',\n",
        "        split=['train', 'test'],\n",
        "        shuffle_files=True,\n",
        "        as_supervised=True,\n",
        "        with_info=True,\n",
        "        data_dir='data/tfds'\n",
        "    )\n",
        "    return ds_train, ds_test, ds_info"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 1:\n",
        ">The necessary modules are imported  on lines 2 - 6.\n",
        "\n",
        ">The load_dataset() method loads the Stanford dogs dataset.\n",
        "\n",
        ">The shuffle_files=True parameter indicates that the dataset files should be shuffled before loading. Shuffling the files helps in randomizing the order of data samples during training.\n",
        "\n",
        ">The as_supervised=True parameter specifies that the data is loaded in a supervised format, where each example consists of an image and its corresponding label."
      ],
      "metadata": {
        "id": "bWawtrXdyqX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SECTION 2\n",
        "total_set, ds_test, ds_info = load_dataset()\n",
        "n_train_samples = tf.data.experimental.cardinality(total_set).numpy()\n",
        "n_validation_samples = int(0.1 * n_train_samples)\n",
        "n_train_samples = n_train_samples - n_validation_samples\n",
        "ds_val = total_set.take(n_validation_samples)\n",
        "ds_train = total_set.skip(n_validation_samples)"
      ],
      "metadata": {
        "id": "wLzssw7Iypet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 2\n",
        "\n",
        "> The overall purpose of Section 2 is to split the dataset into training, validation, and test sets. The validation set is taken from the beginning of the training set, leaving the remaining samples for actual training. The total_set variable contains the entire dataset, while ds_train and ds_val are used for training and validation, respectively.\n",
        "\n",
        ">The variables are stored globally."
      ],
      "metadata": {
        "id": "u6eILMnCxx8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SECTION 3\n",
        "def preprocess_image(image, label, image_size=(224, 224)):\n",
        "    image = tf.image.resize(image, image_size)\n",
        "    image = tf.keras.applications.mobilenet.preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def prepare_for_training(ds_train,ds_val, ds_test, batch_size=32, image_size=(224, 224)):\n",
        "    ds_train = ds_train.map(lambda x, y: preprocess_image(x, y, image_size), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds_train = ds_train.batch(batch_size)\n",
        "    ds_train = ds_train.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    ds_val = ds_val.map(lambda x, y: preprocess_image(x, y, image_size), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds_val = ds_val.batch(batch_size)\n",
        "    ds_val = ds_val.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    ds_test = ds_test.map(lambda x, y: preprocess_image(x, y, image_size), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds_test = ds_test.batch(batch_size)\n",
        "    ds_test = ds_test.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return ds_train, ds_val, ds_test"
      ],
      "metadata": {
        "id": "T2shBvKPwrov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 3\n",
        "\n",
        "> The preprocess image method utilizes tensorflow's built-in preprocess_input() method to transform the input tailored to the MobileNet model architecture. It also resizes the input to a specific resolution, which will be useful in the experiment we are about to set up in the next section.\n",
        "\n",
        "> The prepare_for_training() method maps the preprocessing function to each element in the train , validation and testing sets, batches them into specified batch sizes and returns the updated sets to the caller."
      ],
      "metadata": {
        "id": "qz-lWXvHxyqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SECTION 4\n",
        "def run_experiment(hyperparameters, epoch, get_summary=False):\n",
        "    start = time.time()\n",
        "    for each in hyperparameters:\n",
        "      alpha_, resolution = each\n",
        "\n",
        "      image_size_ = (resolution, resolution)\n",
        "\n",
        "      print(f\"Running experiment with alpha = {alpha_} and resolution = {resolution}\")\n",
        "      model = tf.keras.applications.MobileNet(alpha=alpha_, weights='imagenet', include_top=True,\n",
        "                                              input_shape=(resolution, resolution,3))\n",
        "\n",
        "      for layer in model.layers[:-5]:\n",
        "          layer.trainable = False\n",
        "\n",
        "      lr = 0.001\n",
        "      beta_1 = 0.9\n",
        "      beta_2 = 0.995\n",
        "      epsilon = 1e-08\n",
        "      optimizer = Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
        "\n",
        "      model.compile(\n",
        "          optimizer=optimizer,\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy']\n",
        "      )\n",
        "\n",
        "      train_set,val_set,test_set = prepare_for_training(ds_train,ds_val, ds_test, batch_size=32, image_size=image_size_)\n",
        "\n",
        "      model.fit(train_set,epochs=epoch, batch_size=32, validation_data=val_set)\n",
        "\n",
        "      if get_summary:\n",
        "        model.summary()\n",
        "\n",
        "      epochs = epoch\n",
        "      model.fit(train_set, epochs=epoch)\n",
        "      test_loss, test_accuracy = model.evaluate(test_set)\n",
        "\n",
        "      print(f'Test accuracy: {test_accuracy*100}% for alpha = {alpha_} and resolution = {resolution}')\n",
        "      print(\"_________________________________________________________________________________________________________________________\")\n",
        "      print(\"_________________________________________________________________________________________________________________________\")\n",
        "  end = time.time()\n",
        "  print(f\"Total Time Taken for ALL MODELS: {end-start} seconds\")"
      ],
      "metadata": {
        "id": "VR7FM-Vaw-mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 4\n",
        "\n",
        ">The run_experiment() method orchestrates the entire experiment. It iteratively trains each model using alpha and resolution values passed as a list of tuples.\n",
        "For the model we use MobileNet version 1 pretrained on the ImageNets dataset.\n",
        "\n",
        ">Further we freeze all the convolutional layers of the model on lines 13 and 14 of Section 4 of the code. This gave the authors 3 major benefits.\n",
        "  \n",
        "  >>1. The benefit of transfer learning was utilized by the model. Since it was pretrained on the large and comprehensive ImageNet dataset, it was bound to perform better than if the convolutional layers were updated on each sample.\n",
        "  >>2.It prevented overfitting of our model to Stanford Dogs dataset.\n",
        "  >>3.It reduced the training time by almost 50%.\n",
        "\n",
        "> Lines 16-20 have the code for optimizing the model. The beta1 and beta2 parameters are the exponential decay rates for the first and second moment estimtes in the Adam optimizer.\n",
        "\n",
        "  >>a. The exponential decay rate for the first moment estimates, often denoted as \"beta_1,\" controls how much weight is given to past gradients when computing the running average. Specifically, the first moment estimate at time step t is a weighted average of the gradient at step t and the first moment estimate at step t-1.\n",
        "\n",
        "  >>b. The exponential decay rate for the second moment estimates, often denoted as \"beta_2,\" controls how much weight is given to past squared gradients when computing the running average. Like the first moment estimates, the second moment estimate at time step t is a weighted average of the squared gradient at step t and the second moment estimate at step t-1.\n",
        "\n",
        "  >> Overall both the beta values have an effect of placing a greater emphasis on the recent gradients, which result in smoother trajectories when optimization takes place.\n",
        "\n",
        ">>Lines 22-43 compile and run the model and display the relevant model metrics."
      ],
      "metadata": {
        "id": "hKfmok3RxzPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = (1.0, 0.75, 0.50, 0.25)\n",
        "resolutions = (224, 192, 160, 128)\n",
        "hyperparameters = list(itertools.product(alphas, resolutions))\n",
        "run_experiment(hyperparameters=hyperparameters, epoch=30)"
      ],
      "metadata": {
        "id": "hLvotivcHUAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we define and initialize our width and resolution multiplier arrays and pass them to the run_experiment() method. Below are the metrics collected for the entire experiment with each model running for 30 epochs.\n"
      ],
      "metadata": {
        "id": "cc1TpIlCHU-j"
      }
    }
  ]
}